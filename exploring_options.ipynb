{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51e5c7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from tqdm import tqdm \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import h5py \n",
    "\n",
    "from PIL import Image \n",
    "from scipy import ndimage \n",
    "from PIL import Image\n",
    "\n",
    "from tkinter import Tcl\n",
    "\n",
    "from sklearn.utils import shuffle \n",
    "\n",
    "\n",
    "from preProcessingUtils import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6100118",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'D:\\sagar\\Data'\n",
    "scans = os.listdir(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bfbcbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found  533  ROI and  561  notROI sample\n"
     ]
    }
   ],
   "source": [
    "path_roi = []\n",
    "path_notRoi = []\n",
    "\n",
    "for s in scans:\n",
    "    scan_path = os.path.join(root_dir, s)\n",
    "    for r in os.listdir(os.path.join(scan_path, 'roi')):\n",
    "        path_roi.append((os.path.join(root_dir, s, 'roi', r)))\n",
    "    try:\n",
    "        for nr in os.listdir(os.path.join(scan_path, 'not_roi')):\n",
    "            path_notRoi.append((os.path.join(root_dir, s, 'not_roi', nr)))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print('Found ', len(path_roi), ' ROI and ', len(path_notRoi), ' notROI sample')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3da2c348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffleing and choosing the sample for test and train \n",
    "path_roi = shuffle(path_roi, random_state=3)\n",
    "path_notRoi = shuffle(path_notRoi, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd4755e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_roi_path, test_roi_path = path_roi[0:500], path_roi[500:533]\n",
    "train_notRoi_path, test_notRoi_path = path_notRoi[0:500], path_notRoi[500:561]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45889a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_formatted_data(dataPath, xdim=300, ydim=300, zdim=300):\n",
    "    \n",
    "    print('Loading ', len(dataPath), ' Samples.... ')\n",
    "    \n",
    "    formattedData = np.zeros(shape=(len(dataPath), xdim, ydim, zdim, 1), dtype=np.float32)\n",
    "\n",
    "    for i, afile in enumerate(tqdm(dataPath)):\n",
    "        raw_vol = []\n",
    "        #sorting the slices according to their names like in windows \n",
    "        slices = Tcl().call('lsort', '-dict', os.listdir(afile))\n",
    "        for aSlice in slices:\n",
    "            img = Image.open(os.path.join(afile, aSlice))\n",
    "            imgarray = np.array(img)\n",
    "            raw_vol.append(imgarray)\n",
    "\n",
    "        raw_vol = np.asarray(raw_vol)\n",
    "        raw_vol = np.nan_to_num(raw_vol)\n",
    "        #raw_vol = ndimage.zoom(raw_vol, resize_factor, order=1)\n",
    "        # Normalize the data : 0-1\n",
    "        vol = norm(raw_vol)\n",
    "        formattedData[i, :, :, :, 0] = vol\n",
    "    \n",
    "    print('Loaded ', len(dataPath), ' Samples with shape ', formattedData.shape, '\\n')\n",
    "    return formattedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03499f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  500  Samples.... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [18:28<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded  500  Samples with shape  (500, 300, 300, 300, 1) \n",
      "\n",
      "Loading  33  Samples.... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [01:12<00:00,  2.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded  33  Samples with shape  (33, 300, 300, 300, 1) \n",
      "\n",
      "Loading  500  Samples.... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                               | 10/500 [00:22<18:14,  2.23s/it]D:\\sagar\\roiClassifier\\preProcessingUtils.py:46: RuntimeWarning: overflow encountered in float_scalars\n",
      "  maxVal -= minVal\n",
      "D:\\sagar\\roiClassifier\\preProcessingUtils.py:48: RuntimeWarning: overflow encountered in subtract\n",
      "  v = ((v - minVal)/maxVal)\n",
      "D:\\sagar\\roiClassifier\\preProcessingUtils.py:48: RuntimeWarning: invalid value encountered in true_divide\n",
      "  v = ((v - minVal)/maxVal)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [18:38<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded  500  Samples with shape  (500, 300, 300, 300, 1) \n",
      "\n",
      "Loading  61  Samples.... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [02:19<00:00,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded  61  Samples with shape  (61, 300, 300, 300, 1) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_roi = create_formatted_data(train_roi_path)\n",
    "test_roi = create_formatted_data(test_roi_path)\n",
    "\n",
    "\n",
    "train_notRoi = create_formatted_data(train_notRoi_path)\n",
    "test_notRoi = create_formatted_data(test_notRoi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b0aa308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0dfe942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2ce8427",
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_roi\n",
    "del test_notRoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62866675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the label \n",
    "train_roi_label = []\n",
    "for i in range(len(train_roi_path)):\n",
    "    train_roi_label.append([1, 0])\n",
    "\n",
    "train_roi_label = np.array(train_roi_label)\n",
    "\n",
    "\n",
    "# Creating the label \n",
    "train_notRoi_label = []\n",
    "for i in range(len(train_notRoi_path)):\n",
    "    train_notRoi_label.append([0, 1])\n",
    "\n",
    "train_notRoi_label = np.array(train_notRoi_label)\n",
    "\n",
    "\n",
    "# # Creating the label \n",
    "# test_roi_label = []\n",
    "# for i in range(len(test_roi_path)):\n",
    "#     test_roi_label.append([1, 0])\n",
    "\n",
    "# test_roi_label = np.array(test_roi_label)\n",
    "\n",
    "\n",
    "# # Creating the label \n",
    "# test_notRoi_label = []\n",
    "# for i in range(len(test_notRoi_path)):\n",
    "#     test_notRoi_label.append([0, 1])\n",
    "\n",
    "# test_notRoi_label = np.array(test_notRoi_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b0130a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFeatures = np.concatenate((train_roi, train_notRoi), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd61d55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_roi\n",
    "del train_notRoi\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b13852e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 300, 300, 300, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainFeatures.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2b13dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLabels = np.concatenate((train_roi_label, train_notRoi_label), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7551288d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_notRoi_label\n",
    "del train_roi_label\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b3a7286",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle(trainFeatures, trainLabels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10a2643b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del trainFeatures\n",
    "del trainLabels\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96e3e77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f159f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import BatchNormalization \n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ab8b70f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5905a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Manager\\.conda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 300, 300, 300, 5)  140       \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 150, 150, 150, 5)  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 150, 150, 150, 5)  20        \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 150, 150, 150, 5)  680       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 75, 75, 75, 5)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 75, 75, 75, 5)     20        \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 75, 75, 75, 5)     680       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 37, 37, 37, 5)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 37, 37, 37, 5)     20        \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 37, 37, 37, 5)     680       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 18, 18, 18, 5)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 18, 18, 18, 5)     20        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 29160)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                933152    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 936,534\n",
      "Trainable params: 936,494\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building a model \n",
    "input_shape=X_train.shape[1:]\n",
    "model = models.Sequential()\n",
    "# Conv Layers \n",
    "model.add(layers.Conv3D(5, (3, 3, 3), padding='same', activation ='relu', input_shape=input_shape, data_format='channels_last'))\n",
    "model.add(layers.MaxPooling3D(pool_size=(2,2,2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.Conv3D(5, (3, 3, 3), padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling3D(pool_size=(2,2,2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.Conv3D(5, (3, 3, 3), padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling3D(pool_size=(2,2,2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.Conv3D(5, (3, 3, 3), padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling3D(pool_size=(2,2,2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "\n",
    "# FC layer \n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dropout(rate = 0.1))\n",
    "\n",
    "model.add(layers.Dense(32, activation='relu'))#, kernel_regularizer='l2'))\n",
    "model.add(layers.Dropout(rate = 0.1))\n",
    "model.add(layers.Dense(2, activation='softmax'))#, kernel_regularizer='l2'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "443b052e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "989b4877",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[4,5,150,150,150] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/Adam/gradients/gradients/max_pooling3d/MaxPool3D_grad/MaxPool3DGrad}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6640\\2546930165.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m hist = model.fit(X_train, y_train, batch_size=batch_size, \n\u001b[0;32m      9\u001b[0m                  \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcsv_logger\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                  validation_split=0.1)\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\.conda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 675\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\.conda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3476\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\.conda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[4,5,150,150,150] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/Adam/gradients/gradients/max_pooling3d/MaxPool3D_grad/MaxPool3DGrad}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import CSVLogger \n",
    "csvFile = 'trainwithOrig_' + time.strftime('%m%d%H%M') + '.csv'\n",
    "csv_logger = CSVLogger(csvFile, append=True, separator=';')\n",
    "\n",
    "# Training the model \n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "hist = model.fit(X_train, y_train, batch_size=batch_size, \n",
    "                 epochs=epochs, verbose=1, callbacks=[csv_logger],\n",
    "                 validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ca357323",
   "metadata": {},
   "outputs": [],
   "source": [
    "del tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fbc020f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "755"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986f5f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
